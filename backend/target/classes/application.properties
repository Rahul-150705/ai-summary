# Server
server.port=8080

# File Upload
spring.servlet.multipart.max-file-size=10MB
spring.servlet.multipart.max-request-size=10MB
spring.servlet.multipart.enabled=true

# LLM Provider (openai | claude | gemini)
llm.provider=openai
openai.api.key=${OPENAI_API_KEY:your-openai-api-key-here}
openai.api.url=https://api.openai.com/v1/chat/completions
openai.model=gpt-4

llm.provider=${LLM_PROVIDER:openai}
ollama.api.url=http://localhost:11434/api/generate
ollama.model=llama3.2

claude.api.key=${CLAUDE_API_KEY:your-claude-api-key-here}
claude.api.url=https://api.anthropic.com/v1/messages
claude.model=claude-sonnet-4-6

gemini.api.key=${GEMINI_API_KEY:your-gemini-api-key-here}
gemini.api.url=https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent

# ✅ JWT Configuration
# Use a strong random secret in production (min 256-bit / 32 chars)
jwt.secret=${JWT_SECRET:3f8e2a1b9c7d4e6f0a5b2c8d3e9f1a4b7c0d5e2f8a3b6c9d2e5f0a1b4c7d8e9}
jwt.access-token.expiration=900000
# Access token  = 15 minutes (milliseconds)
jwt.refresh-token.expiration=604800000
# Refresh token = 7 days (milliseconds)

# CORS
cors.allowed.origins=http://localhost:5173,http://localhost:3000

# Database (PostgreSQL — Neon.tech cloud with pgvector)
spring.datasource.url=${DB_URL:jdbc:postgresql://ep-holy-credit-ai5cj1no-pooler.c-4.us-east-1.aws.neon.tech/neondb?sslmode=require&channel_binding=require}
spring.datasource.username=${DB_USERNAME:neondb_owner}
spring.datasource.password=${DB_PASSWORD:npg_2CUmMkLapBA4}
spring.datasource.driver-class-name=org.postgresql.Driver

# SSL required by Neon.tech
spring.datasource.hikari.data-source-properties.sslmode=require

# JPA / Hibernate
spring.jpa.hibernate.ddl-auto=update
spring.jpa.show-sql=false
spring.jpa.properties.hibernate.dialect=org.hibernate.dialect.PostgreSQLDialect
spring.jpa.properties.hibernate.format_sql=true

# Logging
logging.level.com.ai.teachingassistant=DEBUG
logging.level.org.springframework.security=INFO

# ── Spring AI ─────────────────────────────────────────────────────────────
#
# TWO MODES — switch by changing 'rag.embedding.provider' below:
#
#   openai  → Uses OpenAI API  (requires OPENAI_API_KEY, costs money, 1536 dims)
#   ollama  → Uses local Ollama (free, no key needed, runs in Docker, 768 dims)
#
# IMPORTANT: if you switch providers, drop and recreate the vector_store table
# because embedding dimensions differ (1536 vs 768 are incompatible).
#
rag.embedding.provider=${RAG_EMBEDDING_PROVIDER:ollama}

# ── Spring AI — OpenAI (disabled — Ollama is used for RAG embeddings + chat)
# Both starters are on the classpath but we only use Ollama locally.
# Disabling OpenAI auto-config prevents the ambiguous EmbeddingModel bean error.
spring.ai.openai.api-key=${OPENAI_API_KEY:your-openai-api-key-here}
spring.ai.openai.embedding.enabled=false
spring.ai.openai.chat.enabled=false

# ── Spring AI — Ollama (local Docker, free) ────────────────────────────
spring.ai.ollama.base-url=http://localhost:11434
spring.ai.ollama.chat.options.model=llama3.2
spring.ai.ollama.chat.options.temperature=0.2
spring.ai.ollama.embedding.options.model=nomic-embed-text

# ── pgvector Store ──────────────────────────────────────────────────────
# Dimensions MUST match the embedding model:
#   nomic-embed-text  → 768
#   text-embedding-3-small (OpenAI) → 1536
spring.ai.vectorstore.pgvector.initialize-schema=true
spring.ai.vectorstore.pgvector.dimensions=768
spring.ai.vectorstore.pgvector.distance-type=COSINE_DISTANCE
spring.ai.vectorstore.pgvector.index-type=HNSW